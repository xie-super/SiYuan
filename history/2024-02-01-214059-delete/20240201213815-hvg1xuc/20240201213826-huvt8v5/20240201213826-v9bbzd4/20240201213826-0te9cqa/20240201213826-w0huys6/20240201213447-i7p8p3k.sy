{"ID":"20240201213447-i7p8p3k","Spec":"1","Type":"NodeDocument","Properties":{"id":"20240201213447-i7p8p3k","title":"kafka-questions-01","updated":"20240201213447"},"Children":[{"ID":"20240201213448-x9cmqmc","Type":"NodeThematicBreak","Properties":{"id":"20240201213448-x9cmqmc","updated":"20240201213448"}},{"ID":"20240201213449-v3seoan","Type":"NodeParagraph","Properties":{"id":"20240201213449-v3seoan","updated":"20240201213449"},"Children":[{"Type":"NodeText","Data":"title: Kafka常见问题总结"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"category: 高性能"},{"Type":"NodeSoftBreak","Data":"\n","Properties":{"id":""}},{"Type":"NodeText","Data":"tag:"}]},{"ID":"20240201213450-drikpjy","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"MarkerOffset":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213450-drikpjy","updated":"20240201213450"},"Children":[{"ID":"20240201213451-0fssaz6","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"MarkerOffset":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213451-0fssaz6","updated":"20240201213451"},"Children":[{"ID":"20240201213452-qfmycze","Type":"NodeParagraph","Properties":{"id":"20240201213452-qfmycze","updated":"20240201213452"},"Children":[{"Type":"NodeText","Data":"消息队列"}]}]}]},{"ID":"20240201213453-65ssqkb","Type":"NodeThematicBreak","Properties":{"id":"20240201213453-65ssqkb","updated":"20240201213453"}},{"ID":"20240201213454-x2lqb0a","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20240201213454-x2lqb0a","updated":"20240201213454"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 基础"}]},{"ID":"20240201213455-upwc265","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213455-upwc265","updated":"20240201213455"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 是什么？主要应用场景有哪些？"}]},{"ID":"20240201213456-am9hujk","Type":"NodeParagraph","Properties":{"id":"20240201213456-am9hujk","updated":"20240201213456"},"Children":[{"Type":"NodeText","Data":"Kafka 是一个分布式流式处理平台。这到底是什么意思呢？"}]},{"ID":"20240201213457-su6zqu0","Type":"NodeParagraph","Properties":{"id":"20240201213457-su6zqu0","updated":"20240201213457"},"Children":[{"Type":"NodeText","Data":"流平台具有三个关键功能："}]},{"ID":"20240201213458-u4doznc","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213458-u4doznc","updated":"20240201213458"},"Children":[{"ID":"20240201213459-xfi47q4","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213459-xfi47q4","updated":"20240201213459"},"Children":[{"ID":"20240201213460-ivnnkrz","Type":"NodeParagraph","Properties":{"id":"20240201213460-ivnnkrz","updated":"20240201213460"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"消息队列"},{"Type":"NodeText","Data":"：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。"}]}]},{"ID":"20240201213461-4k5b14e","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213461-4k5b14e","updated":"20240201213461"},"Children":[{"ID":"20240201213462-op2i6q7","Type":"NodeParagraph","Properties":{"id":"20240201213462-op2i6q7","updated":"20240201213462"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"容错的持久方式存储记录消息流"},{"Type":"NodeText","Data":"：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。"}]}]},{"ID":"20240201213463-b2x0xfr","Type":"NodeListItem","Data":"3","ListData":{"Typ":1,"Tight":true,"Start":3,"Delimiter":46,"Padding":3,"Marker":"Mw==","Num":3},"Properties":{"id":"20240201213463-b2x0xfr","updated":"20240201213463"},"Children":[{"ID":"20240201213464-ldu96q8","Type":"NodeParagraph","Properties":{"id":"20240201213464-ldu96q8","updated":"20240201213464"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"流式处理平台："},{"Type":"NodeText","Data":" 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。"}]}]}]},{"ID":"20240201213465-do6cssn","Type":"NodeParagraph","Properties":{"id":"20240201213465-do6cssn","updated":"20240201213465"},"Children":[{"Type":"NodeText","Data":"Kafka 主要有两大应用场景："}]},{"ID":"20240201213466-5w2iisk","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213466-5w2iisk","updated":"20240201213466"},"Children":[{"ID":"20240201213467-fw02x7f","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213467-fw02x7f","updated":"20240201213467"},"Children":[{"ID":"20240201213468-8w49g0n","Type":"NodeParagraph","Properties":{"id":"20240201213468-8w49g0n","updated":"20240201213468"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"消息队列"},{"Type":"NodeText","Data":"：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。"}]}]},{"ID":"20240201213469-2m5r8ik","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213469-2m5r8ik","updated":"20240201213469"},"Children":[{"ID":"20240201213470-flo3udt","Type":"NodeParagraph","Properties":{"id":"20240201213470-flo3udt","updated":"20240201213470"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"数据处理："},{"Type":"NodeText","Data":" 构建实时的流数据处理程序来转换或处理数据流。"}]}]}]},{"ID":"20240201213471-i243l3f","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213471-i243l3f","updated":"20240201213471"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"和其他消息队列相比,Kafka 的优势在哪里？"}]},{"ID":"20240201213472-mapzdbo","Type":"NodeParagraph","Properties":{"id":"20240201213472-mapzdbo","updated":"20240201213472"},"Children":[{"Type":"NodeText","Data":"我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下："}]},{"ID":"20240201213473-n1yg5bz","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213473-n1yg5bz","updated":"20240201213473"},"Children":[{"ID":"20240201213474-c9qzm7j","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213474-c9qzm7j","updated":"20240201213474"},"Children":[{"ID":"20240201213475-vyuhq0f","Type":"NodeParagraph","Properties":{"id":"20240201213475-vyuhq0f","updated":"20240201213475"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"极致的性能"},{"Type":"NodeText","Data":"：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。"}]}]},{"ID":"20240201213476-c1xbeq2","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213476-c1xbeq2","updated":"20240201213476"},"Children":[{"ID":"20240201213477-a2nyfxn","Type":"NodeParagraph","Properties":{"id":"20240201213477-a2nyfxn","updated":"20240201213477"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"生态系统兼容性无可匹敌"},{"Type":"NodeText","Data":"：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。"}]}]}]},{"ID":"20240201213478-bga1l98","Type":"NodeParagraph","Properties":{"id":"20240201213478-bga1l98","updated":"20240201213478"},"Children":[{"Type":"NodeText","Data":"实际上在早期的时候 Kafka 并不是一个合格的消息队列，早期的 Kafka 在消息队列领域就像是一个衣衫褴褛的孩子一样，功能不完备并且有一些小问题比如丢失消息、不保证消息可靠性等等。当然，这也和 LinkedIn 最早开发 Kafka 用于处理海量的日志有很大关系，哈哈哈，人家本来最开始就不是为了作为消息队列滴，谁知道后面误打误撞在消息队列领域占据了一席之地。"}]},{"ID":"20240201213479-9ossexb","Type":"NodeParagraph","Properties":{"id":"20240201213479-9ossexb","updated":"20240201213479"},"Children":[{"Type":"NodeText","Data":"随着后续的发展，这些短板都被 Kafka 逐步修复完善。所以，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Kafka 作为消息队列不可靠这个说法已经过时！"}]},{"ID":"20240201213480-0a1b1wt","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213480-0a1b1wt","updated":"20240201213480"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"队列模型了解吗？Kafka 的消息模型知道吗？"}]},{"ID":"20240201213481-cey2gjy","Type":"NodeBlockquote","Properties":{"id":"20240201213481-cey2gjy","updated":"20240201213481"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213482-qhb74nd","Type":"NodeParagraph","Properties":{"id":"20240201213482-qhb74nd","updated":"20240201213482"},"Children":[{"Type":"NodeText","Data":"题外话：早期的 JMS 和 AMQP 属于消息服务领域权威组织所做的相关的标准，我在 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"a","TextMarkAHref":"https://github.com/Snailclimb/JavaGuide","TextMarkTextContent":"JavaGuide"},{"Type":"NodeText","Data":"的 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"a","TextMarkAHref":"https://github.com/Snailclimb/JavaGuide#%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E4%B8%AD%E9%97%B4%E4%BB%B6","TextMarkTextContent":"《消息队列其实很简单》"},{"Type":"NodeText","Data":"这篇文章中介绍过。但是，这些标准的进化跟不上消息队列的演进速度，这些标准实际上已经属于废弃状态。所以，可能存在的情况是：不同的消息队列都有自己的一套消息模型。"}]}]},{"ID":"20240201213483-xekb26p","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20240201213483-xekb26p","updated":"20240201213483"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"队列模型：早期的消息模型"}]},{"ID":"20240201213484-7s72waq","Type":"NodeParagraph","Properties":{"id":"20240201213484-7s72waq","updated":"20240201213484"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"队列模型","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B23.png","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20240201213485-pw5ky2k","Type":"NodeParagraph","Properties":{"id":"20240201213485-pw5ky2k","updated":"20240201213485"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。"},{"Type":"NodeText","Data":" 比如：我们生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）"}]},{"ID":"20240201213486-766hozq","Type":"NodeParagraph","Properties":{"id":"20240201213486-766hozq","updated":"20240201213486"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"队列模型存在的问题："}]},{"ID":"20240201213487-spuctwa","Type":"NodeParagraph","Properties":{"id":"20240201213487-spuctwa","updated":"20240201213487"},"Children":[{"Type":"NodeText","Data":"假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容。"}]},{"ID":"20240201213488-ffa56sn","Type":"NodeParagraph","Properties":{"id":"20240201213488-ffa56sn","updated":"20240201213488"},"Children":[{"Type":"NodeText","Data":"这种情况，队列模型就不好解决了。很多比较杠精的人就说：我们可以为每个消费者创建一个单独的队列，让生产者发送多份。这是一种非常愚蠢的做法，浪费资源不说，还违背了使用消息队列的目的。"}]},{"ID":"20240201213489-q3qbugo","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20240201213489-q3qbugo","updated":"20240201213489"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"发布-订阅模型:Kafka 消息模型"}]},{"ID":"20240201213490-ho23vn1","Type":"NodeParagraph","Properties":{"id":"20240201213490-ho23vn1","updated":"20240201213490"},"Children":[{"Type":"NodeText","Data":"发布-订阅模型主要是为了解决队列模型存在的问题。"}]},{"ID":"20240201213491-hjfkktm","Type":"NodeParagraph","Properties":{"id":"20240201213491-hjfkktm","updated":"20240201213491"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"发布订阅模型","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://oss.javaguide.cn/java-guide-blog/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B.png","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20240201213492-5i5tuos","Type":"NodeParagraph","Properties":{"id":"20240201213492-5i5tuos","updated":"20240201213492"},"Children":[{"Type":"NodeText","Data":"发布订阅模型（Pub-Sub） 使用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"主题（Topic）"},{"Type":"NodeText","Data":" 作为消息通信载体，类似于"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"广播模式"},{"Type":"NodeText","Data":"；发布者发布一条消息，该消息通过主题传递给所有的订阅者，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"在一条消息广播之后才订阅的用户则是收不到该条消息的"},{"Type":"NodeText","Data":"。"}]},{"ID":"20240201213493-u8cqpax","Type":"NodeParagraph","Properties":{"id":"20240201213493-u8cqpax","updated":"20240201213493"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。"}]},{"ID":"20240201213494-4hxs8pz","Type":"NodeParagraph","Properties":{"id":"20240201213494-4hxs8pz","updated":"20240201213494"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Kafka 采用的就是发布 - 订阅模型。"}]},{"ID":"20240201213495-w39o6pj","Type":"NodeBlockquote","Properties":{"id":"20240201213495-w39o6pj","updated":"20240201213495"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213496-ol5jsou","Type":"NodeParagraph","Properties":{"id":"20240201213496-ol5jsou","updated":"20240201213496"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。"}]}]},{"ID":"20240201213497-z4asjw1","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20240201213497-z4asjw1","updated":"20240201213497"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 核心概念"}]},{"ID":"20240201213498-z6ge8oc","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213498-z6ge8oc","updated":"20240201213498"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"什么是 Producer、Consumer、Broker、Topic、Partition？"}]},{"ID":"20240201213499-x1u1zte","Type":"NodeParagraph","Properties":{"id":"20240201213499-x1u1zte","updated":"20240201213499"},"Children":[{"Type":"NodeText","Data":"Kafka 将生产者发布的消息发送到 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Topic（主题）"},{"Type":"NodeText","Data":" 中，需要这些消息的消费者可以订阅这些 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Topic（主题）"},{"Type":"NodeText","Data":"，如下图所示："}]},{"ID":"20240201213500-854j7ni","Type":"NodeParagraph","Properties":{"id":"20240201213500-854j7ni","updated":"20240201213500"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue20210507200944439.png","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20240201213501-9p90ado","Type":"NodeParagraph","Properties":{"id":"20240201213501-9p90ado","updated":"20240201213501"},"Children":[{"Type":"NodeText","Data":"上面这张图也为我们引出了，Kafka 比较重要的几个概念："}]},{"ID":"20240201213502-ojbi8v9","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213502-ojbi8v9","updated":"20240201213502"},"Children":[{"ID":"20240201213503-a75ti0a","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213503-a75ti0a","updated":"20240201213503"},"Children":[{"ID":"20240201213504-pxx3pbf","Type":"NodeParagraph","Properties":{"id":"20240201213504-pxx3pbf","updated":"20240201213504"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Producer（生产者）"},{"Type":"NodeText","Data":" : 产生消息的一方。"}]}]},{"ID":"20240201213505-cjfipk0","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213505-cjfipk0","updated":"20240201213505"},"Children":[{"ID":"20240201213506-szr1pfn","Type":"NodeParagraph","Properties":{"id":"20240201213506-szr1pfn","updated":"20240201213506"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Consumer（消费者）"},{"Type":"NodeText","Data":" : 消费消息的一方。"}]}]},{"ID":"20240201213507-oplr6hi","Type":"NodeListItem","Data":"3","ListData":{"Typ":1,"Tight":true,"Start":3,"Delimiter":46,"Padding":3,"Marker":"Mw==","Num":3},"Properties":{"id":"20240201213507-oplr6hi","updated":"20240201213507"},"Children":[{"ID":"20240201213508-f0o2miq","Type":"NodeParagraph","Properties":{"id":"20240201213508-f0o2miq","updated":"20240201213508"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Broker（代理）"},{"Type":"NodeText","Data":" : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。"}]}]}]},{"ID":"20240201213509-0zgmp7i","Type":"NodeParagraph","Properties":{"id":"20240201213509-0zgmp7i","updated":"20240201213509"},"Children":[{"Type":"NodeText","Data":"同时，你一定也注意到每个 Broker 中又包含了 Topic 以及 Partition 这两个重要的概念："}]},{"ID":"20240201213510-is817la","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213510-is817la","updated":"20240201213510"},"Children":[{"ID":"20240201213511-vwuieeh","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213511-vwuieeh","updated":"20240201213511"},"Children":[{"ID":"20240201213512-fpwnxv4","Type":"NodeParagraph","Properties":{"id":"20240201213512-fpwnxv4","updated":"20240201213512"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Topic（主题）"},{"Type":"NodeText","Data":" : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。"}]}]},{"ID":"20240201213513-5w0pfx4","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213513-5w0pfx4","updated":"20240201213513"},"Children":[{"ID":"20240201213514-1o3m4ty","Type":"NodeParagraph","Properties":{"id":"20240201213514-1o3m4ty","updated":"20240201213514"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Partition（分区）"},{"Type":"NodeText","Data":" : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。"}]}]}]},{"ID":"20240201213515-77loe4z","Type":"NodeBlockquote","Properties":{"id":"20240201213515-77loe4z","updated":"20240201213515"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213516-0pdh7os","Type":"NodeParagraph","Properties":{"id":"20240201213516-0pdh7os","updated":"20240201213516"},"Children":[{"Type":"NodeText","Data":"划重点："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。这样是不是更好理解一点？"}]}]},{"ID":"20240201213517-z892sk2","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213517-z892sk2","updated":"20240201213517"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 的多副本机制了解吗？带来了什么好处？"}]},{"ID":"20240201213518-ev23svx","Type":"NodeParagraph","Properties":{"id":"20240201213518-ev23svx","updated":"20240201213518"},"Children":[{"Type":"NodeText","Data":"还有一点我觉得比较重要的是 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。"}]},{"ID":"20240201213519-eifs01o","Type":"NodeBlockquote","Properties":{"id":"20240201213519-eifs01o","updated":"20240201213519"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213520-f56g7co","Type":"NodeParagraph","Properties":{"id":"20240201213520-f56g7co","updated":"20240201213520"},"Children":[{"Type":"NodeText","Data":"生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。"}]}]},{"ID":"20240201213521-12pvipx","Type":"NodeParagraph","Properties":{"id":"20240201213521-12pvipx","updated":"20240201213521"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？"}]},{"ID":"20240201213522-5zyajzb","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213522-5zyajzb","updated":"20240201213522"},"Children":[{"ID":"20240201213523-bsstqab","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213523-bsstqab","updated":"20240201213523"},"Children":[{"ID":"20240201213524-q1av6ak","Type":"NodeParagraph","Properties":{"id":"20240201213524-q1av6ak","updated":"20240201213524"},"Children":[{"Type":"NodeText","Data":"Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。"}]}]},{"ID":"20240201213525-zpqkghx","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213525-zpqkghx","updated":"20240201213525"},"Children":[{"ID":"20240201213526-uaxmpqe","Type":"NodeParagraph","Properties":{"id":"20240201213526-uaxmpqe","updated":"20240201213526"},"Children":[{"Type":"NodeText","Data":"Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。"}]}]}]},{"ID":"20240201213527-kxgr5e5","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20240201213527-kxgr5e5","updated":"20240201213527"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"Zookeeper 和 Kafka"}]},{"ID":"20240201213528-j7fh2di","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213528-j7fh2di","updated":"20240201213528"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Zookeeper 在 Kafka 中的作用是什么？"}]},{"ID":"20240201213529-2pjapy1","Type":"NodeBlockquote","Properties":{"id":"20240201213529-2pjapy1","updated":"20240201213529"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213530-8depma4","Type":"NodeParagraph","Properties":{"id":"20240201213530-8depma4","updated":"20240201213530"},"Children":[{"Type":"NodeText","Data":"要想搞懂 zookeeper 在 Kafka 中的作用 一定要自己搭建一个 Kafka 环境然后自己进 zookeeper 去看一下有哪些文件夹和 Kafka 有关，每个节点又保存了什么信息。 一定不要光看不实践，这样学来的也终会忘记！这部分内容参考和借鉴了这篇文章："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"a","TextMarkAHref":"https://www.jianshu.com/p/a036405f989c","TextMarkTextContent":"https://www.jianshu.com/p/a036405f989c"},{"Type":"NodeText","Data":" 。"}]}]},{"ID":"20240201213531-5fhsiz0","Type":"NodeParagraph","Properties":{"id":"20240201213531-5fhsiz0","updated":"20240201213531"},"Children":[{"Type":"NodeText","Data":"下图就是我的本地 Zookeeper ，它成功和我本地的 Kafka 关联上（以下文件夹结构借助 idea 插件 Zookeeper tool 实现）。"}]},{"ID":"20240201213532-p42v8t7","Type":"NodeHTMLBlock","Data":"\u003cdiv\u003e\n\u003cimg src=\"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/zookeeper-kafka.jpg\" style=\"zoom:50%;\" /\u003e\n\u003c/div\u003e","HtmlBlockType":7,"Properties":{"id":"20240201213532-p42v8t7","updated":"20240201213532"}},{"ID":"20240201213533-dc6hfed","Type":"NodeParagraph","Properties":{"id":"20240201213533-dc6hfed","updated":"20240201213533"},"Children":[{"Type":"NodeText","Data":"ZooKeeper 主要为 Kafka 提供元数据的管理的功能。"}]},{"ID":"20240201213534-si4hhsy","Type":"NodeParagraph","Properties":{"id":"20240201213534-si4hhsy","updated":"20240201213534"},"Children":[{"Type":"NodeText","Data":"从图中我们可以看出，Zookeeper 主要为 Kafka 做了下面这些事情："}]},{"ID":"20240201213535-rd1vu9n","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213535-rd1vu9n","updated":"20240201213535"},"Children":[{"ID":"20240201213536-yp58wzz","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213536-yp58wzz","updated":"20240201213536"},"Children":[{"ID":"20240201213537-nxcnwui","Type":"NodeParagraph","Properties":{"id":"20240201213537-nxcnwui","updated":"20240201213537"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Broker 注册"},{"Type":"NodeText","Data":"：在 Zookeeper 上会有一个专门"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"用来进行 Broker 服务器列表记录"},{"Type":"NodeText","Data":"的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"/brokers/ids"},{"Type":"NodeText","Data":" 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去"}]}]},{"ID":"20240201213538-gzuqvpj","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213538-gzuqvpj","updated":"20240201213538"},"Children":[{"ID":"20240201213539-0978rje","Type":"NodeParagraph","Properties":{"id":"20240201213539-0978rje","updated":"20240201213539"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Topic 注册"},{"Type":"NodeText","Data":"：在 Kafka 中，同一个"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Topic 的消息会被分成多个分区"},{"Type":"NodeText","Data":"并将其分布在多个 Broker 上，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"这些分区信息及与 Broker 的对应关系"},{"Type":"NodeText","Data":"也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"/brokers/topics/my-topic/Partitions/0"},{"Type":"NodeText","Data":"、"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"/brokers/topics/my-topic/Partitions/1"}]}]},{"ID":"20240201213540-soqrc1w","Type":"NodeListItem","Data":"3","ListData":{"Typ":1,"Tight":true,"Start":3,"Delimiter":46,"Padding":3,"Marker":"Mw==","Num":3},"Properties":{"id":"20240201213540-soqrc1w","updated":"20240201213540"},"Children":[{"ID":"20240201213541-gfd9pg4","Type":"NodeParagraph","Properties":{"id":"20240201213541-gfd9pg4","updated":"20240201213541"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"负载均衡"},{"Type":"NodeText","Data":"：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。"}]}]},{"ID":"20240201213542-c9dpu03","Type":"NodeListItem","Data":"4","ListData":{"Typ":1,"Tight":true,"Start":4,"Delimiter":46,"Padding":3,"Marker":"NA==","Num":4},"Properties":{"id":"20240201213542-c9dpu03","updated":"20240201213542"},"Children":[{"ID":"20240201213543-4lic090","Type":"NodeParagraph","Properties":{"id":"20240201213543-4lic090","updated":"20240201213543"},"Children":[{"Type":"NodeText","Data":"……"}]}]}]},{"ID":"20240201213544-99v3gku","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213544-99v3gku","updated":"20240201213544"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"使用 Kafka 能否不引入 Zookeeper?"}]},{"ID":"20240201213545-wtwus29","Type":"NodeParagraph","Properties":{"id":"20240201213545-wtwus29","updated":"20240201213545"},"Children":[{"Type":"NodeText","Data":"在 Kafka 2.8 之前，Kafka 最被大家诟病的就是其重度依赖于 Zookeeper。在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构，让你可以以一种轻量级的方式来使用 Kafka。"}]},{"ID":"20240201213546-cjj8h5k","Type":"NodeParagraph","Properties":{"id":"20240201213546-cjj8h5k","updated":"20240201213546"},"Children":[{"Type":"NodeText","Data":"不过，要提示一下："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"如果要使用 KRaft 模式的话，建议选择较高版本的 Kafka，因为这个功能还在持续完善优化中。Kafka 3.3.1 版本是第一个将 KRaft（Kafka Raft）共识协议标记为生产就绪的版本。"}]},{"ID":"20240201213547-sufkrt1","Type":"NodeParagraph","Properties":{"id":"20240201213547-sufkrt1","updated":"20240201213547"},"Children":[{"Type":"NodeText","Data":"![]("},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"a","TextMarkAHref":"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/kafka3.3.1-kraft-","TextMarkTextContent":"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/kafka3.3.1-kraft-"},{"Type":"NodeText","Data":" production-ready.png)"}]},{"ID":"20240201213548-bhoxu1e","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20240201213548-bhoxu1e","updated":"20240201213548"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 消费顺序、消息丢失和重复消费"}]},{"ID":"20240201213549-qg4y4n3","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213549-qg4y4n3","updated":"20240201213549"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 如何保证消息的消费顺序？"}]},{"ID":"20240201213550-i3y4cp1","Type":"NodeParagraph","Properties":{"id":"20240201213550-i3y4cp1","updated":"20240201213550"},"Children":[{"Type":"NodeText","Data":"我们在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如我们同时发了 2 个消息，这 2 个消息对应的操作分别对应的数据库操作是："}]},{"ID":"20240201213551-zot3bey","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213551-zot3bey","updated":"20240201213551"},"Children":[{"ID":"20240201213552-1yy7st7","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213552-1yy7st7","updated":"20240201213552"},"Children":[{"ID":"20240201213553-acrlfel","Type":"NodeParagraph","Properties":{"id":"20240201213553-acrlfel","updated":"20240201213553"},"Children":[{"Type":"NodeText","Data":"更改用户会员等级。"}]}]},{"ID":"20240201213554-y0p2kim","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213554-y0p2kim","updated":"20240201213554"},"Children":[{"ID":"20240201213555-aok8kx4","Type":"NodeParagraph","Properties":{"id":"20240201213555-aok8kx4","updated":"20240201213555"},"Children":[{"Type":"NodeText","Data":"根据会员等级计算订单价格。"}]}]}]},{"ID":"20240201213556-u68bi5u","Type":"NodeParagraph","Properties":{"id":"20240201213556-u68bi5u","updated":"20240201213556"},"Children":[{"Type":"NodeText","Data":"假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。"}]},{"ID":"20240201213557-s52nskp","Type":"NodeParagraph","Properties":{"id":"20240201213557-s52nskp","updated":"20240201213557"},"Children":[{"Type":"NodeText","Data":"我们知道 Kafka 中 Partition(分区)是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的 Partition(分区) 又存在于 Topic(主题) 这个概念中，并且我们可以给特定 Topic 指定多个 Partition。"}]},{"ID":"20240201213558-9bql6up","Type":"NodeParagraph","Properties":{"id":"20240201213558-9bql6up","updated":"20240201213558"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/KafkaTopicPartionsLayout.png","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20240201213559-baqi16f","Type":"NodeParagraph","Properties":{"id":"20240201213559-baqi16f","updated":"20240201213559"},"Children":[{"Type":"NodeText","Data":"每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Kafka 只能为我们保证 Partition(分区) 中的消息有序。"}]},{"ID":"20240201213560-qold77c","Type":"NodeBlockquote","Properties":{"id":"20240201213560-qold77c","updated":"20240201213560"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213561-2pant0f","Type":"NodeParagraph","Properties":{"id":"20240201213561-2pant0f","updated":"20240201213561"},"Children":[{"Type":"NodeText","Data":"消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。"}]}]},{"ID":"20240201213562-cg9zcc2","Type":"NodeParagraph","Properties":{"id":"20240201213562-cg9zcc2","updated":"20240201213562"},"Children":[{"Type":"NodeText","Data":"所以，我们就有一种很简单的保证消息消费顺序的方法："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"1 个 Topic 只对应一个 Partition"},{"Type":"NodeText","Data":"。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。"}]},{"ID":"20240201213563-uieczbs","Type":"NodeParagraph","Properties":{"id":"20240201213563-uieczbs","updated":"20240201213563"},"Children":[{"Type":"NodeText","Data":"Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。"}]},{"ID":"20240201213564-dtcn9z4","Type":"NodeParagraph","Properties":{"id":"20240201213564-dtcn9z4","updated":"20240201213564"},"Children":[{"Type":"NodeText","Data":"总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法："}]},{"ID":"20240201213565-u1p1o69","Type":"NodeList","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213565-u1p1o69","updated":"20240201213565"},"Children":[{"ID":"20240201213566-2flvnk5","Type":"NodeListItem","Data":"1","ListData":{"Typ":1,"Tight":true,"Start":1,"Delimiter":46,"Padding":3,"Marker":"MQ==","Num":1},"Properties":{"id":"20240201213566-2flvnk5","updated":"20240201213566"},"Children":[{"ID":"20240201213567-a9631v3","Type":"NodeParagraph","Properties":{"id":"20240201213567-a9631v3","updated":"20240201213567"},"Children":[{"Type":"NodeText","Data":"1 个 Topic 只对应一个 Partition。"}]}]},{"ID":"20240201213568-ry6jeep","Type":"NodeListItem","Data":"2","ListData":{"Typ":1,"Tight":true,"Start":2,"Delimiter":46,"Padding":3,"Marker":"Mg==","Num":2},"Properties":{"id":"20240201213568-ry6jeep","updated":"20240201213568"},"Children":[{"ID":"20240201213569-9rp3pdp","Type":"NodeParagraph","Properties":{"id":"20240201213569-9rp3pdp","updated":"20240201213569"},"Children":[{"Type":"NodeText","Data":"（推荐）发送消息的时候指定 key/Partition。"}]}]}]},{"ID":"20240201213570-vhq5dcy","Type":"NodeParagraph","Properties":{"id":"20240201213570-vhq5dcy","updated":"20240201213570"},"Children":[{"Type":"NodeText","Data":"当然不仅仅只有上面两种方法，上面两种方法是我觉得比较好理解的，"}]},{"ID":"20240201213571-mwovo8t","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213571-mwovo8t","updated":"20240201213571"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 如何保证消息不丢失？"}]},{"ID":"20240201213572-o3a96r9","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20240201213572-o3a96r9","updated":"20240201213572"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"生产者丢失消息的情况"}]},{"ID":"20240201213573-opj7dbe","Type":"NodeParagraph","Properties":{"id":"20240201213573-opj7dbe","updated":"20240201213573"},"Children":[{"Type":"NodeText","Data":"生产者(Producer) 调用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"send"},{"Type":"NodeText","Data":"方法发送消息之后，消息可能因为网络问题并没有发送过去。"}]},{"ID":"20240201213574-rv1ybv8","Type":"NodeParagraph","Properties":{"id":"20240201213574-rv1ybv8","updated":"20240201213574"},"Children":[{"Type":"NodeText","Data":"所以，我们不能默认在调用"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"send"},{"Type":"NodeText","Data":"方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"send"},{"Type":"NodeText","Data":" 方法发送消息实际上是异步的操作，我们可以通过 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"get()"},{"Type":"NodeText","Data":"方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下："}]},{"ID":"20240201213575-z117qw9","Type":"NodeBlockquote","Properties":{"id":"20240201213575-z117qw9","updated":"20240201213575"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213576-4ycuq2w","Type":"NodeParagraph","Properties":{"id":"20240201213576-4ycuq2w","updated":"20240201213576"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"详细代码见我的这篇文章："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong a","TextMarkAHref":"https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==\u0026mid=2247486269\u0026idx=2\u0026sn=ec00417ad641dd8c3d145d74cafa09ce\u0026chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de\u0026token=1633957262\u0026lang=zh_CN#rd","TextMarkTextContent":"Kafka 系列第三篇！10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?"}]}]},{"ID":"20240201213577-o9vk2c9","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"amF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213577-o9vk2c9","updated":"20240201213577"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"amF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"SendResult\u003cString, Object\u003e sendResult = kafkaTemplate.send(topic, o).get();\nif (sendResult.getRecordMetadata() != null) {\n  logger.info(\"生产者成功发送消息到\" + sendResult.getProducerRecord().topic() + \"-\u003e \" + sendRe\n              sult.getProducerRecord().value().toString());\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213578-6kxs4e3","Type":"NodeParagraph","Properties":{"id":"20240201213578-6kxs4e3","updated":"20240201213578"},"Children":[{"Type":"NodeText","Data":"但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下："}]},{"ID":"20240201213579-n7r6u2v","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"amF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213579-n7r6u2v","updated":"20240201213579"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"amF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"        ListenableFuture\u003cSendResult\u003cString, Object\u003e\u003e future = kafkaTemplate.send(topic, o);\n        future.addCallback(result -\u003e logger.info(\"生产者成功发送消息到topic:{} partition:{}的消息\", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),\n                ex -\u003e logger.error(\"生产者发送消失败，原因：{}\", ex.getMessage()));\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213580-yc9qcqs","Type":"NodeParagraph","Properties":{"id":"20240201213580-yc9qcqs","updated":"20240201213580"},"Children":[{"Type":"NodeText","Data":"如果消息发送失败的话，我们检查失败的原因之后重新发送即可！"}]},{"ID":"20240201213581-g7slj2c","Type":"NodeParagraph","Properties":{"id":"20240201213581-g7slj2c","updated":"20240201213581"},"Children":[{"Type":"NodeText","Data":"另外，这里推荐为 Producer 的"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"retries"},{"Type":"NodeText","Data":"（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了。"}]},{"ID":"20240201213582-jzu8pnr","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20240201213582-jzu8pnr","updated":"20240201213582"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"消费者丢失消息的情况"}]},{"ID":"20240201213583-kiuhga5","Type":"NodeParagraph","Properties":{"id":"20240201213583-kiuhga5","updated":"20240201213583"},"Children":[{"Type":"NodeText","Data":"我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。"}]},{"ID":"20240201213584-cr6gzs5","Type":"NodeParagraph","Properties":{"id":"20240201213584-cr6gzs5","updated":"20240201213584"},"Children":[{"Type":"NodeImage","Properties":{"id":""},"Children":[{"Type":"NodeBang","Data":"!","Properties":{"id":""}},{"Type":"NodeOpenBracket","Data":"[","Properties":{"id":""}},{"Type":"NodeLinkText","Data":"kafka offset","Properties":{"id":""}},{"Type":"NodeCloseBracket","Data":"]","Properties":{"id":""}},{"Type":"NodeOpenParen","Data":"(","Properties":{"id":""}},{"Type":"NodeLinkDest","Data":"https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/kafka-offset.jpg","Properties":{"id":""}},{"Type":"NodeCloseParen","Data":")","Properties":{"id":""}}]}]},{"ID":"20240201213585-i3h2j8b","Type":"NodeParagraph","Properties":{"id":"20240201213585-i3h2j8b","updated":"20240201213585"},"Children":[{"Type":"NodeText","Data":"当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。"}]},{"ID":"20240201213586-cl53vsc","Type":"NodeParagraph","Properties":{"id":"20240201213586-cl53vsc","updated":"20240201213586"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。"},{"Type":"NodeText","Data":" 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。"}]},{"ID":"20240201213587-5q1a309","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20240201213587-5q1a309","updated":"20240201213587"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"#### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 弄丢了消息"}]},{"ID":"20240201213588-qnliyhs","Type":"NodeParagraph","Properties":{"id":"20240201213588-qnliyhs","updated":"20240201213588"},"Children":[{"Type":"NodeText","Data":"我们知道 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。"}]},{"ID":"20240201213589-0cdpb6y","Type":"NodeParagraph","Properties":{"id":"20240201213589-0cdpb6y","updated":"20240201213589"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。"}]},{"ID":"20240201213590-ao1us9l","Type":"NodeParagraph","Properties":{"id":"20240201213590-ao1us9l","updated":"20240201213590"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"设置 acks = all"}]},{"ID":"20240201213591-48upebh","Type":"NodeParagraph","Properties":{"id":"20240201213591-48upebh","updated":"20240201213591"},"Children":[{"Type":"NodeText","Data":"解决办法就是我们设置 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"acks = all"},{"Type":"NodeText","Data":"。acks 是 Kafka 生产者(Producer) 很重要的一个参数。"}]},{"ID":"20240201213592-gl7vlcq","Type":"NodeParagraph","Properties":{"id":"20240201213592-gl7vlcq","updated":"20240201213592"},"Children":[{"Type":"NodeText","Data":"acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"acks = all"},{"Type":"NodeText","Data":" 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高."}]},{"ID":"20240201213593-v747yw1","Type":"NodeParagraph","Properties":{"id":"20240201213593-v747yw1","updated":"20240201213593"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"设置 replication.factor \u0026gt;= 3"}]},{"ID":"20240201213594-mmgv82b","Type":"NodeParagraph","Properties":{"id":"20240201213594-mmgv82b","updated":"20240201213594"},"Children":[{"Type":"NodeText","Data":"为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"replication.factor \u0026gt;= 3"},{"Type":"NodeText","Data":"。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。"}]},{"ID":"20240201213595-py0zzbk","Type":"NodeParagraph","Properties":{"id":"20240201213595-py0zzbk","updated":"20240201213595"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"设置 min.insync.replicas \u0026gt; 1"}]},{"ID":"20240201213596-fxi0g8o","Type":"NodeParagraph","Properties":{"id":"20240201213596-fxi0g8o","updated":"20240201213596"},"Children":[{"Type":"NodeText","Data":"一般情况下我们还需要设置 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"min.insync.replicas\u0026gt; 1"},{"Type":"NodeText","Data":" ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"min.insync.replicas"},{"Type":"NodeText","Data":" 的默认值为 1 ，在实际生产中应尽量避免默认值 1。"}]},{"ID":"20240201213597-nj4xmfs","Type":"NodeParagraph","Properties":{"id":"20240201213597-nj4xmfs","updated":"20240201213597"},"Children":[{"Type":"NodeText","Data":"但是，为了保证整个 Kafka 服务的高可用性，你需要确保 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"replication.factor \u0026gt; min.insync.replicas"},{"Type":"NodeText","Data":" 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"replication.factor = min.insync.replicas + 1"},{"Type":"NodeText","Data":"。"}]},{"ID":"20240201213598-bja29bb","Type":"NodeParagraph","Properties":{"id":"20240201213598-bja29bb","updated":"20240201213598"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"设置 unclean.leader.election.enable = false"}]},{"ID":"20240201213599-t1oyh3y","Type":"NodeBlockquote","Properties":{"id":"20240201213599-t1oyh3y","updated":"20240201213599"},"Children":[{"Type":"NodeBlockquoteMarker","Data":"\u003e ","Properties":{"id":""}},{"ID":"20240201213600-8kgq4s9","Type":"NodeParagraph","Properties":{"id":"20240201213600-8kgq4s9","updated":"20240201213600"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false"}]}]},{"ID":"20240201213601-58jz0p0","Type":"NodeParagraph","Properties":{"id":"20240201213601-58jz0p0","updated":"20240201213601"},"Children":[{"Type":"NodeText","Data":"我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"unclean.leader.election.enable = false"},{"Type":"NodeText","Data":" 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。"}]},{"ID":"20240201213602-6djmohn","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213602-6djmohn","updated":"20240201213602"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 如何保证消息不重复消费？"}]},{"ID":"20240201213603-h19isoi","Type":"NodeParagraph","Properties":{"id":"20240201213603-h19isoi","updated":"20240201213603"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"kafka 出现消息重复消费的原因："}]},{"ID":"20240201213604-a9oshau","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213604-a9oshau","updated":"20240201213604"},"Children":[{"ID":"20240201213605-bojwapu","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213605-bojwapu","updated":"20240201213605"},"Children":[{"ID":"20240201213606-w7xaghy","Type":"NodeParagraph","Properties":{"id":"20240201213606-w7xaghy","updated":"20240201213606"},"Children":[{"Type":"NodeText","Data":"服务端侧已经消费的数据没有成功提交 offset（根本原因）。"}]}]},{"ID":"20240201213607-444286h","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213607-444286h","updated":"20240201213607"},"Children":[{"ID":"20240201213608-5dxyspe","Type":"NodeParagraph","Properties":{"id":"20240201213608-5dxyspe","updated":"20240201213608"},"Children":[{"Type":"NodeText","Data":"Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。"}]}]}]},{"ID":"20240201213609-kxgaeuh","Type":"NodeParagraph","Properties":{"id":"20240201213609-kxgaeuh","updated":"20240201213609"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"解决方案："}]},{"ID":"20240201213610-lwlc540","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213610-lwlc540","updated":"20240201213610"},"Children":[{"ID":"20240201213611-po7awh5","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213611-po7awh5","updated":"20240201213611"},"Children":[{"ID":"20240201213612-kf6u1bu","Type":"NodeParagraph","Properties":{"id":"20240201213612-kf6u1bu","updated":"20240201213612"},"Children":[{"Type":"NodeText","Data":"消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。"}]}]},{"ID":"20240201213613-vohvv5w","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213613-vohvv5w","updated":"20240201213613"},"Children":[{"ID":"20240201213614-5jdr166","Type":"NodeParagraph","Properties":{"id":"20240201213614-5jdr166","updated":"20240201213614"},"Children":[{"Type":"NodeText","Data":"将 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong code","TextMarkTextContent":"enable.auto.commit"},{"Type":"NodeText","Data":" 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"什么时候提交 offset 合适？"}]},{"ID":"20240201213615-9l4dfvr","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213615-9l4dfvr","updated":"20240201213615"},"Children":[{"ID":"20240201213616-ear8aat","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213616-ear8aat","updated":"20240201213616"},"Children":[{"ID":"20240201213617-b0p8fq9","Type":"NodeParagraph","Properties":{"id":"20240201213617-b0p8fq9","updated":"20240201213617"},"Children":[{"Type":"NodeText","Data":"处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样"}]}]},{"ID":"20240201213618-bqzc1x5","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213618-bqzc1x5","updated":"20240201213618"},"Children":[{"ID":"20240201213619-qxn9quu","Type":"NodeParagraph","Properties":{"id":"20240201213619-qxn9quu","updated":"20240201213619"},"Children":[{"Type":"NodeText","Data":"拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。"}]}]}]}]}]},{"ID":"20240201213620-cfypmlk","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20240201213620-cfypmlk","updated":"20240201213620"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"Kafka 重试机制"}]},{"ID":"20240201213621-enhqd4v","Type":"NodeParagraph","Properties":{"id":"20240201213621-enhqd4v","updated":"20240201213621"},"Children":[{"Type":"NodeText","Data":"在 Kafka 如何保证消息不丢失这里，我们提到了 Kafka 的重试机制。由于这部分内容较为重要，我们这里再来详细介绍一下。"}]},{"ID":"20240201213622-ckux9zl","Type":"NodeParagraph","Properties":{"id":"20240201213622-ckux9zl","updated":"20240201213622"},"Children":[{"Type":"NodeText","Data":"网上关于 Spring Kafka 的默认重试机制文章很多，但大多都是过时的，和实际运行结果完全不一样。以下是根据 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"a","TextMarkAHref":"https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka/2.9.3","TextMarkTextContent":"spring-kafka-2.9.3"},{"Type":"NodeText","Data":" 源码重新梳理一下。"}]},{"ID":"20240201213623-868mplt","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213623-868mplt","updated":"20240201213623"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"消费失败会怎么样？"}]},{"ID":"20240201213624-0hkn7vh","Type":"NodeParagraph","Properties":{"id":"20240201213624-0hkn7vh","updated":"20240201213624"},"Children":[{"Type":"NodeText","Data":"在消费过程中，当其中一个消息消费异常时，会不会卡住后续队列消息的消费？这样业务岂不是卡住了？"}]},{"ID":"20240201213625-ci6yljc","Type":"NodeParagraph","Properties":{"id":"20240201213625-ci6yljc","updated":"20240201213625"},"Children":[{"Type":"NodeText","Data":"生产者代码："}]},{"ID":"20240201213626-joj0nzo","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213626-joj0nzo","updated":"20240201213626"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":" for (int i = 0; i \u003c 10; i++) {\n   kafkaTemplate.send(KafkaConst.TEST_TOPIC, String.valueOf(i))\n }\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213627-m449loy","Type":"NodeParagraph","Properties":{"id":"20240201213627-m449loy","updated":"20240201213627"},"Children":[{"Type":"NodeText","Data":"消费者消代码："}]},{"ID":"20240201213628-jssc69x","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213628-jssc69x","updated":"20240201213628"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"   @KafkaListener(topics = {KafkaConst.TEST_TOPIC},groupId = \"apple\")\n   private void customer(String message) throws InterruptedException {\n       log.info(\"kafka customer:{}\",message);\n       Integer n = Integer.parseInt(message);\n       if (n%5==0){\n           throw new  RuntimeException();\n       }\n   }\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213629-e4l0l4x","Type":"NodeParagraph","Properties":{"id":"20240201213629-e4l0l4x","updated":"20240201213629"},"Children":[{"Type":"NodeText","Data":"在默认配置下，当消费异常会进行重试，重试多次后会跳过当前消息，继续进行后续消息的消费，不会一直卡在当前消息。下面是一段消费的日志，可以看出当 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"test-0@95"},{"Type":"NodeText","Data":" 重试多次后会被跳过。"}]},{"ID":"20240201213630-tbkolah","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213630-tbkolah","updated":"20240201213630"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"2023-08-10 12:03:32.918 DEBUG 9700 --- [ntainer#0-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Skipping seek of: test-0@95\n2023-08-10 12:03:32.918 TRACE 9700 --- [ntainer#0-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Seeking: test-0 to: 96\n2023-08-10 12:03:32.918  INFO 9700 --- [ntainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-apple-1, groupId=apple] Seeking to offset 96 for partition test-0\n\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213631-hut66fa","Type":"NodeParagraph","Properties":{"id":"20240201213631-hut66fa","updated":"20240201213631"},"Children":[{"Type":"NodeText","Data":"因此，即使某个消息消费异常，Kafka 消费者仍然能够继续消费后续的消息，不会一直卡在当前消息，保证了业务的正常进行。"}]},{"ID":"20240201213632-is2gdyq","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213632-is2gdyq","updated":"20240201213632"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"默认会重试多少次？"}]},{"ID":"20240201213633-v036j1b","Type":"NodeParagraph","Properties":{"id":"20240201213633-v036j1b","updated":"20240201213633"},"Children":[{"Type":"NodeText","Data":"默认配置下，消费异常会进行重试，重试次数是多少, 重试是否有时间间隔？"}]},{"ID":"20240201213634-a8yj6dr","Type":"NodeParagraph","Properties":{"id":"20240201213634-a8yj6dr","updated":"20240201213634"},"Children":[{"Type":"NodeText","Data":"看源码 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"FailedRecordTracker"},{"Type":"NodeText","Data":" 类有个 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"recovered"},{"Type":"NodeText","Data":" 函数，返回 Boolean 值判断是否要进行重试，下面是这个函数中判断是否重试的逻辑："}]},{"ID":"20240201213635-ulj7lpa","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"amF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213635-ulj7lpa","updated":"20240201213635"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"amF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"\t@Override\n\tpublic boolean recovered(ConsumerRecord \u003c\u003c ? , ? \u003e record, Exception exception,\n\t    @Nullable MessageListenerContainer container,\n\t    @Nullable Consumer \u003c\u003c ? , ? \u003e consumer) throws InterruptedException {\n\n\t    if (this.noRetries) {\n         // 不支持重试\n\t        attemptRecovery(record, exception, null, consumer);\n\t        return true;\n\t    }\n     // 取已经失败的消费记录集合\n\t    Map \u003c TopicPartition, FailedRecord \u003e map = this.failures.get();\n\t    if (map == null) {\n\t        this.failures.set(new HashMap \u003c \u003e ());\n\t        map = this.failures.get();\n\t    }\n     //  获取消费记录所在的Topic和Partition\n\t    TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition());\n\t    FailedRecord failedRecord = getFailedRecordInstance(record, exception, map, topicPartition);\n     // 通知注册的重试监听器，消息投递失败\n\t    this.retryListeners.forEach(rl - \u003e\n\t        rl.failedDelivery(record, exception, failedRecord.getDeliveryAttempts().get()));\n\t    // 获取下一次重试的时间间隔\n    long nextBackOff = failedRecord.getBackOffExecution().nextBackOff();\n\t    if (nextBackOff != BackOffExecution.STOP) {\n\t        this.backOffHandler.onNextBackOff(container, exception, nextBackOff);\n\t        return false;\n\t    } else {\n\t        attemptRecovery(record, exception, topicPartition, consumer);\n\t        map.remove(topicPartition);\n\t        if (map.isEmpty()) {\n\t            this.failures.remove();\n\t        }\n\t        return true;\n\t    }\n\t}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213636-ineqw41","Type":"NodeParagraph","Properties":{"id":"20240201213636-ineqw41","updated":"20240201213636"},"Children":[{"Type":"NodeText","Data":"其中， "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"BackOffExecution.STOP"},{"Type":"NodeText","Data":" 的值为 -1。"}]},{"ID":"20240201213637-0uci0g6","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"amF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213637-0uci0g6","updated":"20240201213637"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"amF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"@FunctionalInterface\npublic interface BackOffExecution {\n\n\tlong STOP = -1;\n\tlong nextBackOff();\n\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213638-cbqj6b3","Type":"NodeParagraph","Properties":{"id":"20240201213638-cbqj6b3","updated":"20240201213638"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"nextBackOff"},{"Type":"NodeText","Data":" 的值调用 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"BackOff"},{"Type":"NodeText","Data":" 类的 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"nextBackOff()"},{"Type":"NodeText","Data":" 函数。如果当前执行次数大于最大执行次数则返回 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"STOP"},{"Type":"NodeText","Data":"，既超过这个最大执行次数后才会停止重试。"}]},{"ID":"20240201213639-dyep28c","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213639-dyep28c","updated":"20240201213639"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"public long nextBackOff() {\n  this.currentAttempts++;\n  if (this.currentAttempts \u003c= getMaxAttempts()) {\n    return getInterval();\n  }\n  else {\n    return STOP;\n  }\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213640-2j43rt7","Type":"NodeParagraph","Properties":{"id":"20240201213640-2j43rt7","updated":"20240201213640"},"Children":[{"Type":"NodeText","Data":"那么这个 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"getMaxAttempts"},{"Type":"NodeText","Data":" 的值又是多少呢？回到最开始，当执行出错会进入 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultErrorHandler"},{"Type":"NodeText","Data":" 。"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultErrorHandler"},{"Type":"NodeText","Data":" 默认的构造函数是："}]},{"ID":"20240201213641-1luuhhi","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213641-1luuhhi","updated":"20240201213641"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"public DefaultErrorHandler() {\n  this(null, SeekUtils.DEFAULT_BACK_OFF);\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213642-rfz6mpf","Type":"NodeParagraph","Properties":{"id":"20240201213642-rfz6mpf","updated":"20240201213642"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"SeekUtils.DEFAULT_BACK_OFF"},{"Type":"NodeText","Data":" 定义的是:"}]},{"ID":"20240201213643-pqxoh95","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213643-pqxoh95","updated":"20240201213643"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"public static final int DEFAULT_MAX_FAILURES = 10;\n\npublic static final FixedBackOff DEFAULT_BACK_OFF = new FixedBackOff(0, DEFAULT_MAX_FAILURES - 1);\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213644-41i764b","Type":"NodeParagraph","Properties":{"id":"20240201213644-41i764b","updated":"20240201213644"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DEFAULT_MAX_FAILURES"},{"Type":"NodeText","Data":" 的值是 10，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"currentAttempts"},{"Type":"NodeText","Data":" 从 0 到 9，所以总共会执行 10 次，每次重试的时间间隔为 0。"}]},{"ID":"20240201213645-cj9vviz","Type":"NodeParagraph","Properties":{"id":"20240201213645-cj9vviz","updated":"20240201213645"},"Children":[{"Type":"NodeText","Data":"最后，简单总结一下：Kafka 消费者在默认配置下会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败。"}]},{"ID":"20240201213646-kcweu3v","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213646-kcweu3v","updated":"20240201213646"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"如何自定义重试次数以及时间间隔?"}]},{"ID":"20240201213647-ggacui9","Type":"NodeParagraph","Properties":{"id":"20240201213647-ggacui9","updated":"20240201213647"},"Children":[{"Type":"NodeText","Data":"从上面的代码可以知道，默认错误处理器的重试次数以及时间间隔是由 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"FixedBackOff"},{"Type":"NodeText","Data":" 控制的，"},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"FixedBackOff"},{"Type":"NodeText","Data":" 是 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultErrorHandler"},{"Type":"NodeText","Data":" 初始化时默认的。所以自定义重试次数以及时间间隔，只需要在 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultErrorHandler"},{"Type":"NodeText","Data":" 初始化的时候传入自定义的 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"FixedBackOff"},{"Type":"NodeText","Data":" 即可。重新实现一个 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"KafkaListenerContainerFactory"},{"Type":"NodeText","Data":" ，调用 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"setCommonErrorHandler"},{"Type":"NodeText","Data":" 设置新的自定义的错误处理器就可以实现。"}]},{"ID":"20240201213648-1qf1kw3","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213648-1qf1kw3","updated":"20240201213648"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"@Bean\npublic KafkaListenerContainerFactory kafkaListenerContainerFactory(ConsumerFactory\u003cString, String\u003e consumerFactory) {\n    ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory();\n    // 自定义重试时间间隔以及次数\n    FixedBackOff fixedBackOff = new FixedBackOff(1000, 5);\n    factory.setCommonErrorHandler(new DefaultErrorHandler(fixedBackOff));\n    factory.setConsumerFactory(consumerFactory);\n    return factory;\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213649-1m3uyo9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213649-1m3uyo9","updated":"20240201213649"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"如何在重试失败后进行告警?"}]},{"ID":"20240201213650-t6cbf0p","Type":"NodeParagraph","Properties":{"id":"20240201213650-t6cbf0p","updated":"20240201213650"},"Children":[{"Type":"NodeText","Data":"自定义重试失败后逻辑，需要手动实现，以下是一个简单的例子，重写 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultErrorHandler"},{"Type":"NodeText","Data":" 的 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"handleRemaining"},{"Type":"NodeText","Data":" 函数，加上自定义的告警等操作。"}]},{"ID":"20240201213651-296jbw1","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213651-296jbw1","updated":"20240201213651"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"@Slf4j\npublic class DelErrorHandler extends DefaultErrorHandler {\n\n    public DelErrorHandler(FixedBackOff backOff) {\n        super(null,backOff);\n    }\n\n    @Override\n    public void handleRemaining(Exception thrownException, List\u003cConsumerRecord\u003c?, ?\u003e\u003e records, Consumer\u003c?, ?\u003e consumer, MessageListenerContainer container) {\n        super.handleRemaining(thrownException, records, consumer, container);\n        log.info(\"重试多次失败\");\n        // 自定义操作\n    }\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213652-bfvrueh","Type":"NodeParagraph","Properties":{"id":"20240201213652-bfvrueh","updated":"20240201213652"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"DefaultErrorHandler"},{"Type":"NodeText","Data":" 只是默认的一个错误处理器，Spring Kafka 还提供了 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"CommonErrorHandler"},{"Type":"NodeText","Data":" 接口。手动实现 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"CommonErrorHandler"},{"Type":"NodeText","Data":" 就可以实现更多的自定义操作，有很高的灵活性。例如根据不同的错误类型，实现不同的重试逻辑以及业务逻辑等。"}]},{"ID":"20240201213653-wkr2d6l","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20240201213653-wkr2d6l","updated":"20240201213653"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"### ","Properties":{"id":""}},{"Type":"NodeText","Data":"重试失败后的数据如何再次处理?"}]},{"ID":"20240201213654-6uwz9sf","Type":"NodeParagraph","Properties":{"id":"20240201213654-6uwz9sf","updated":"20240201213654"},"Children":[{"Type":"NodeText","Data":"当达到最大重试次数后，数据会直接被跳过，继续向后进行。当代码修复后，如何重新消费这些重试失败的数据呢？"}]},{"ID":"20240201213655-a0btqqa","Type":"NodeParagraph","Properties":{"id":"20240201213655-a0btqqa","updated":"20240201213655"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"strong","TextMarkTextContent":"死信队列（Dead Letter Queue，简称 DLQ）"},{"Type":"NodeText","Data":" 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被\"丢弃\"或\"死亡\"的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。"}]},{"ID":"20240201213656-q95subg","Type":"NodeParagraph","Properties":{"id":"20240201213656-q95subg","updated":"20240201213656"},"Children":[{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"@RetryableTopic"},{"Type":"NodeText","Data":" 是 Spring Kafka 中的一个注解,它用于配置某个 Topic 支持消息重试，更推荐使用这个注解来完成重试。"}]},{"ID":"20240201213657-81jeq98","Type":"NodeCodeBlock","IsFencedCodeBlock":true,"CodeBlockFenceChar":96,"CodeBlockFenceLen":3,"CodeBlockOpenFence":"YGBg","CodeBlockInfo":"SmF2YQ==","CodeBlockCloseFence":"YGBg","Properties":{"id":"20240201213657-81jeq98","updated":"20240201213657"},"Children":[{"Type":"NodeCodeBlockFenceOpenMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}},{"Type":"NodeCodeBlockFenceInfoMarker","CodeBlockInfo":"SmF2YQ==","Properties":{"id":""}},{"Type":"NodeCodeBlockCode","Data":"// 重试 5 次，重试间隔 100 毫秒,最大间隔 1 秒\n@RetryableTopic(\n        attempts = \"5\",\n        backoff = @Backoff(delay = 100, maxDelay = 1000)\n)\n@KafkaListener(topics = {KafkaConst.TEST_TOPIC}, groupId = \"apple\")\nprivate void customer(String message) {\n    log.info(\"kafka customer:{}\", message);\n    Integer n = Integer.parseInt(message);\n    if (n % 5 == 0) {\n        throw new RuntimeException();\n    }\n    System.out.println(n);\n}\n","Properties":{"id":""}},{"Type":"NodeCodeBlockFenceCloseMarker","Data":"```","CodeBlockFenceLen":3,"Properties":{"id":""}}]},{"ID":"20240201213658-lz2n9p3","Type":"NodeParagraph","Properties":{"id":"20240201213658-lz2n9p3","updated":"20240201213658"},"Children":[{"Type":"NodeText","Data":"当达到最大重试次数后，如果仍然无法成功处理消息，消息会被发送到对应的死信队列中。对于死信队列的处理，既可以用 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"@DltHandler"},{"Type":"NodeText","Data":" 处理，也可以使用 "},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"code","TextMarkTextContent":"@KafkaListener"},{"Type":"NodeText","Data":" 重新消费。"}]},{"ID":"20240201213659-dea7mf0","Type":"NodeHeading","HeadingLevel":2,"Properties":{"id":"20240201213659-dea7mf0","updated":"20240201213659"},"Children":[{"Type":"NodeHeadingC8hMarker","Data":"## ","Properties":{"id":""}},{"Type":"NodeText","Data":"参考"}]},{"ID":"20240201213660-4klsy2g","Type":"NodeList","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213660-4klsy2g","updated":"20240201213660"},"Children":[{"ID":"20240201213661-3ovi8od","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213661-3ovi8od","updated":"20240201213661"},"Children":[{"ID":"20240201213662-g3p9ofy","Type":"NodeParagraph","Properties":{"id":"20240201213662-g3p9ofy","updated":"20240201213662"},"Children":[{"Type":"NodeText","Data":"Kafka 官方文档："},{"Type":"NodeTextMark","Properties":{"id":""},"TextMarkType":"a","TextMarkAHref":"https://kafka.apache.org/documentation/","TextMarkTextContent":"https://kafka.apache.org/documentation/"}]}]},{"ID":"20240201213663-2ihvt9h","Type":"NodeListItem","Data":"-","ListData":{"Tight":true,"BulletChar":45,"Padding":2,"Marker":"LQ==","Num":-1},"Properties":{"id":"20240201213663-2ihvt9h","updated":"20240201213663"},"Children":[{"ID":"20240201213664-ytf00vm","Type":"NodeParagraph","Properties":{"id":"20240201213664-ytf00vm","updated":"20240201213664"},"Children":[{"Type":"NodeText","Data":"极客时间—《Kafka 核心技术与实战》第 11 节：无消息丢失配置怎么实现？"}]}]}]},{"ID":"20240201213665-66elhsl","Type":"NodeHTMLBlock","Data":"\u003cdiv\u003e\n\u003c!-- @include: @article-footer.snippet.md --\u003e\n\u003c/div\u003e","HtmlBlockType":2,"Properties":{"id":"20240201213665-66elhsl","updated":"20240201213665"}}]}